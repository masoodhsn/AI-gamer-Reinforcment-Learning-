from RL_Lib import QLearning, SARSA
import gymnasium as gym
import time

# Ø³Ø§Ø®Øª Ù…Ø­ÛŒØ· Cliff Walking
env = gym.make("CliffWalking-v0", render_mode="anis")  # ansi = text mode render

# Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… (Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ SARSA Ù‡Ù… ØªØ³Øª Ú©Ù†ÛŒ)
agent = SARSA(env, alpha=0.1, gamma=0.99, epsilon=0.1)

# Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
agent.training(episodes=2000, max_steps=200)
agent.save_model("cliff_q_model.pkl")

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡
env = gym.make("CliffWalking-v0", render_mode="human") 
agent = QLearning(env, alpha=0.1, gamma=0.99, epsilon=0.1)
agent.model_load("cliff_q_model.pkl")
# ØªØ³Øª Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø¨ØµØ±ÛŒ (Ù…ØªÙ†ÛŒ)
num_episodes = 2
for ep in range(num_episodes):
    state = env.reset()
    if isinstance(state, tuple):
        state = state[0]

    total_reward = 0
    done = False

    print(f"\nðŸŽ® Episode {ep + 1} starting...")
    #print(env.render(), end='\r')

    for step in range(100):
        # Ø§Ù†ØªØ®Ø§Ø¨ Ø¹Ù…Ù„ Ø¨Ø§ Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡
        action = agent.action(state, deterministic=True)

        next_state, reward, done, info = agent._step_env(action)
        total_reward += reward
        state = next_state

        # Ù†Ù…Ø§ÛŒØ´ ÙˆØ¶Ø¹ÛŒØª Ù…Ø­ÛŒØ· Ø¯Ø± Ù‡Ø± Ú¯Ø§Ù…
        #print(env.render(),end='\r')
        time.sleep(0.2)

        if done:
            print(f"âœ… Episode {ep + 1} finished. Total reward: {total_reward}")
            break

env.close()
